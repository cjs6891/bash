Terminal Printing

https://linux.die.net/man/1/echo

echo, puts a new line after every "echo" invocation by default, printf does not

double quotes "" can't print special characters, i.e. a ! -or- ?

# echo "Hello!"
-bash: !": event not found

# echo 'Hello!'
Hello!

variable substitution doesn't work with single quotes ''


https://linux.die.net/man/1/printf

printf takes "" text delimited by spaces, by default printf doesn't have new line by default like the echo command; it has to be specified with \n.

# printf "Hello World."
Hello World.[root@el7_blog.local]#

# printf "Hello World.\n"
Hello World.
[root@el7_blog.local]#

Colorizing
http://tldp.org/LDP/abs/html/colorizing.html

 - - - - - 

Variables & Environmental Variables

In BASH the type for every variable is string with or without quotes

To view all the environmental variables issued to a terminal issue the # env command. 

# pgrep to obtain pid(s) for running processes

https://linux.die.net/man/1/pgrep

# pgrep httpd
8499
8500
8501

obtain environment variables of PID by using

# cat /proc/PID/environ

# cat /proc/8499/environ
LANG=CPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/binNOTIFY_SOCKET=/run/systemd/notify

use "tr" for substitution, ex. substitute '\0' with '\n'

https://linux.die.net/man/1/tr

# cat /proc/8499/environ | tr '\0' '\n'
LANG=C
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin
NOTIFY_SOCKET=/run/systemd/notify

set variables:
apple_count=5

IF Variable has a space use '' -or- ""
output='Hello World!'

print variables
# echo $apple_count
5

# echo ${apple_count}
5

# echo $output
Hello World!

# echo ${output}
Hello World!

the # export command is used to set the env variable

# env | grep HISTSIZE
HISTSIZE=1000

# export HISTSIZE=2500
# env | grep HISTSIZE
HISTSIZE=2500

add new path to $PATH variable

# PATH="$PATH:/root/System_Administration"
# export PATH
# echo $PATH

finding the length of a string

# length=${#var}
# var=0123456789
echo ${#var}
10

Identifying the current shell
To identify the shell which is currently being used, use the SHELL environment variable.

# echo $SHELL
/bin/bash

#!/bin/bash


Checking for super user (root)

if [ $UID -ne 0 ]; then
  echo "You're NOT root, please run as root."
else
  echo "You're root, be careful..."
fi

Modifying the Bash prompt string
(username@hostname:~$)

The PS1 environment variable defines the primary prompt. The default prompt is defined by a line in the ~/.bashrc file

\u = username
\h = hostname
\W = current working directory

# echo $PS1
[\u@\h \W]\$

Function to prepend to environment variables
Environment variables are often used to store a list of paths of where to search for executables, libraries, and so on. Example, $PATH

add "/root/System_Administration" to $PATH variable

# echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

# export PATH="$PATH:/root/System_Administration"
# echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/System_Administration


Math with the shell
The Bash shell performs basic arithmetic operations using the let, (( )), and [] commands. The expr and bc utilities are used to perform advanced operations.

# no1=8
# no2=4
# let result=$no1+no2
# echo $result
12

Other uses of let command are as follows:

increment:
# echo $no1
8

# let no1++
# echo $no1
9

decrement
# echo $no2
4
# let no2--
# echo $no2
3

shorthands
add 6 to no1
# echo $no1
9

# let no1+=6
# echo $no1
15

subtract 2 from no2
# echo $no2
3

# let no2-=2
# echo $no2
1

The [] operator is used in the same way as the let command
# echo $no1 && echo $no2
15
1

# result=$[ no1 + no2 ] && echo $result
16

The (( )) operator can also be used
# result=$(( no1 + 100 )) && echo $result
115

The expr expression can be used for basic operations
# result=`expr 3 + 4`
# echo $result
7

# echo $no1
15

# result=$(expr $no1 + 10)
# echo $result
25

The preceding methods do not support floating point numbers, and operate on integers only.

The bc application, the precision calculator, is an advanced utility for mathematical operations. It has a wide range of options. We can perform floating point arithmetic and use advanced functions.

# echo "4 * 0.56" | bc
2.24

# no=54
# result=`echo "$no * 1.5" | bc`
# echo $result
81.0

scale decimal places
# echo "scale=2;22/7" | bc
3.14
# echo "scale=3;22/7" | bc
3.142
# echo "scale=4;22/7" | bc
3.1428

# echo "sqrt(100)" | bc
10

# echo "10^2" | bc
100

Playing with file descriptors and redirection
File descriptors are integers associated with the input and output streams. The best-known file descriptors are stdin, stdout, and stderr. The contents of one stream can be redirected to another.

Shell scripts frequently use standard input (stdin), standard output (stdout), and standard error (stderr). A script can redirect output to a file with the greater-than symbol. Text generated by a command may be normal output or an error message. By default, both normal output (stdout) and error messages (stderr) are sent to the display. The two streams can be separated by specifying a specific descriptor for each stream.


File descriptors are integers associated with an opened file or data stream. File descriptors 0, 1, and 2 are reserved:

0: stdin
1: stdout
2: stderr

The redirection operators (> and >>) send output to a file instead of the terminal. The > and >> operators behave slightly differently. Both redirect output to a file, but the single greater-than symbol (>) empties the file and then writes to it, whereas the double greater-than symbol (>>) adds the output to the end of the existing file.

By default, the redirection operates on standard output. To explicitly take a specific file descriptor, you must prefix the descriptor number to the operator.

If you are familiar with file access in other programming languages, you may be familiar with the modes for opening files. These three modes are commonly used:
 - Read mode
 - Write with append mode
 - Write with truncate mode

The < operator reads from the file to stdin. The > operator writes to a file with truncation (data is written to the target file after truncating the contents). The >> operator writes to a file by appending (data is appended to the existing file contents and the contents of the target file will not be lost).

Use the greater-than symbol (>) to add text to a file:
# echo "Hello." > tmp.txt

*** If tmp.txt already exists, the single greater-than sign (>) will delete any previous contents

# cat tmp.txt
Hello.

Use double-greater-than (>>) to append text to a file:
# echo 'Good Bye!' >> tmp.txt
# cat tmp.txt
Hello.
Good Bye!

When a command exits because of an error, it returns a nonzero exit status. The command returns zero when it terminates after successful completion. The return status is available in the special variable $? (run echo $? immediately after the command execution statement to print the exit status).

# echo $?

You can redirect stderr to one file and stdout to another file.
# cmd 2>stderr.txt 1>stdout.txt

It is also possible to redirect stderr and stdout to a single file by converting stderr to stdout using this preferred method:
# cmd 2>&1 allOutput.txt

This can be done even using an alternate approach:
$ cmd &> output.txt 

If you don't want to see or save any error messages, you can redirect the stderr output to /dev/null, which removes it completely.

The tee command reads from stdin and redirects the input data to stdout and one or more files.

In the following code, the stdin data is received by the tee command. It writes a copy of stdout to the output.txt file and sends another copy as stdin for the next commandn $ cat -n. The cat -n command puts a line number for each line received from stdin and writes it into stdout:

$ cat a* | tee output.txt | cat -n
cat: a1.txt: Permission denied
     1  alfa2
     2  alfa

$ cat output.txt
alfa2
alfa

*** The tee command reads only from stdin

*** By default, the tee command overwrites the file. Including the -a option will force it to append the new data.

To send two copies of the input to stdout, use - for the filename argument:

$ echo 'Hello World!' | tee -
Hello World!
Hello World!

Alternately, we can use /dev/stdin as the output filename to use stdin.Similarly, use /dev/stderr for standard error and /dev/stdout for standard output. These are special device files that correspond to stdin, stderr, and stdout.

Redirection from a file to a command
We can read data from a file as stdin with the less-than symbol (<):

$ cat < a.txt
alfa


Arrays and associative arrays
Arrays allow a script to store a collection of data as separate entities using indices (indexes). Bash supports both regular arrays that use integers as the array index, and associative arrays, which use a string as the array index. Regular arrays should be used when the data is organized numerically, for example, a set of successive iterations. Associative arrays can be used when the data is organized by a string, for example, host names.

Arrays can be defined using different techniques:

Define an array using a list of values in a single line:
# array_var=(test1 test2 test3 test4)
** Values will be stored in consecutive locations starting from index 0

firstArray=(one two three four five six)

Print the contents of an array at a given index using the following commands:
# echo ${firstArray[0]}
one

Print all of the values in an array as a list, using the following commands:
# echo ${firstArray[*]}
one two three four five six

Alternately, you can use the following command:
# echo ${firstArray[@]}
one two three four five six

Print the length of an array (the number of elements in an array):
# echo ${#firstArray[*]}
6

Alternately, define an array as a set of index-value pairs:
# array_var[0]="test1"
# array_var[1]="test2"
# array_var[2]="test3"
# array_var[3]="test4"
# array_var[4]="test5"
# array_var[5]="test6"

# secondArray[0]=alfa
# secondArray[1]=bravo
# secondArray[3]=charlie
# secondArray[4]=delta

Print the contents of an array at a given index using the following commands:
# echo ${secondArray[0]}
alfa

Print all of the values in an array as a list, using the following commands:
# echo ${secondArray[*]}
alfa bravo charlie delta

Alternately, you can use the following command:
# echo ${secondArray[@]}
alfa bravo charlie delta

Print the length of an array (the number of elements in an array):
# echo ${#secondArray[*]}
4

associative arrays
An associative array can use any text data as an array index. A declaration statement is required to define a variable name as an associative array.

# declare -A fruit_value

# fruit_value=([apple]='$1.00' [orange]='$0.50')

# echo "Price Per Apple: ${fruit_value[apple]}"
Price Per Apple: $1.00


Listing of associative indexes (also works with standard arrays)
# echo ${!fruit_value[*]}
orange apple

Alternatively
# echo ${!fruit_value[@]}
orange apple

Visiting aliases
An alias is a shortcut to replace typing a long-command sequence.

Create an alias:
$ alias new_command='command sequence'

# alias yca='yum clean all'

The alias command is temporary: aliases exist until we close the current terminal. To make an alias available to all shells, add this statement to the ~/.bashrc file. Commands in ~/.bashrc are always executed when a new interactive shell process is spawned

# echo 'alias yca="yum clean all"' >> ~/.bashrc

To remove an alias, remove its entry from ~/.bashrc (if any) or use the unalias command.

*** When you create an alias, if the item being aliased already exists, it will be replaced by this newly aliased command for that user.

Escaping aliases
Given how easy it is to create an alias to masquerade as a native command, you should not run aliased commands as a privileged user. We can ignore any aliases currently defined, by escaping the command we want to run.

$ \command

The \ character escapes the command, running it without any aliased changes. When running privileged commands on an untrusted environment, it is always a good security practice to ignore aliases by prefixing the command with \. The attacker might have aliased the privileged command with his/her own custom command, to steal critical information that is provided by the user to the command.

Listing aliases
The alias command lists the currently defined aliases:

# alias
alias cp='cp -i'
alias egrep='egrep --color=auto'
alias fgrep='fgrep --color=auto'
alias grep='grep --color=auto'
alias l.='ls -d .* --color=auto'
alias ll='ls -l --color=auto'
alias ls='ls --color=auto'
alias mv='mv -i'
alias rm='rm -i'

Grabbing information about the terminal
While writing command-line shell scripts, we often need to manipulate information about the current terminal, such as the number of columns, rows, cursor positions, masked password fields, and so on.

The tput and stty commands are utilities used for terminal manipulations.

Return the number of columns and rows in a terminal:
# tput cols
80

# tput lines
24

Return the current terminal name:
# tput longname
xterm terminal emulator (X Window System)

Move the cursor to a 100,100 position:
# tput cup 100 100

Set the terminal background color:
# tput setb 1

*** The value of n can be a value in the range of 0 to 7

Set the terminal foreground color:
# tput setf 1

*** The value of n can be a value in the range of 0 to 7

*** Some commands including the common color ls may reset the foreground and background color, example # ls --color=auto

Make text bold, using this command:
# tput bold

Perform start and end underlining:
# tput smul
# tput rmul

To delete from the cursor to the end of the line, use the following command:
# tput ed

A script should not display the characters while entering a password. The following example demonstrates disabling character echo with the stty command:

 - - - - - START SCRIPT - - - - - 
#!/bin/sh
#Filename: password.sh

echo -e "Enter password: "

# disable echo before reading password
stty -echo

read password
# re-enable echo

stty echo
echo
echo Password read.
 - - - - - END SCRIPT - - - - - 

Getting and setting dates and delays
A time delay is used to wait a set amount of time(such as 1 second) during the program execution, or to monitor a task every few seconds (or every few months). Working with times and dates requires an understanding of how time and date are represented and manipulated. 

Dates can be printed in a variety of formats. Internally, dates are stored as an integer number of seconds since 00:00:00 1970-01-01. This is called epoch or Unix time.

Read the date:
# date
Tue Jul 25 15:52:36 EDT 2017

Print the epoch time:
# date +%s
1501012376

Convert the date string into epoch:
# date --date "09/09/1986" +%s
526622400

# date --date "Tue Sep  9 00:00:00 EDT 1986" +%s
526622400

The --date option defines a date string as input. We can use any date formatting options to print the output.

# date --date "Jan 20 2001" +%A
Saturday

Use a combination of format strings prefixed with + as an argument for the date command, to print the date in the format of your choice.

# date "+%Y.%m.%d"
2017.07.25

Set the date and time:
# date -s "Formatted date string"
# date -s "21 June 2009 11:01:22"

*** On a system connected to a network, you'll want to use ntpdate to set the date and time:/usr/sbin/ntpdate -s time-b.nist.gov

The rule for optimizing your code is to measure first. The date command can be used to time how long it takes a set of commands to execute:

 - - - - - START SCRIPT - - - - -
 #!/bin/bash
start=$(date +%s)
/usr/bin/sleep 5
end=$(date +%s)
difference=$(( end - start))
echo Time taken to execute commands is $difference seconds.
 - - - - - END SCRIPT - - - - -

*** The date command's minimum resolution is one second. A better method for timing commands is the time command:
# time /usr/bin/sleep 5

real    0m5.001s
user    0m0.000s
sys     0m0.002s

Date component					Format
Weekday							%a (for example, Sat)
								%A (for example, Saturday)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Month 							%b (for example, Nov)
								%B (for example, November)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Day 							%d (for example, 31)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Date in format (mm/dd/yy)		%D (for example, 10/18/10)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Year 							%y (for example, 10)
								%Y (for example, 2010)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Hour							%I or %H (For example, 08)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Minute 							%M (for example, 33)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Second 							%S (for example, 10)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Nano Second 					%N (for example, 695208515)
 - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
Epoch Unix 						%s (for example, 1290049486)

Producing delays in a script
The sleep command will delay a script's execution period of time given in seconds. 

# sleep 10


Debugging the script
Debugging frequently takes longer than writing code. A feature every programming language should implement is to produce trace information when something unexpected happens. Debugging information can be read to understand what caused the program to behave in an unexpected fashion. 

Add the -x option to enable debug tracing of a shell script.
# /bin/bash -x sleep.sh

Debug only portions of the script using set -x and set +x. Consider this example:
 - - - - - START SCRIPT - - - - -
#!/bin/bash

for i in {1..6};
do
    set -x
    echo $i
    set +x
done
echo "Script executed"
 - - - - - END SCRIPT - - - - -

The aforementioned debugging methods are provided by Bash built-ins. They produce debugging information in a fixed format. In many cases, we need debugging information in our own format. We can define a _DEBUG environment variable to enable and disable debugging and generate messages in our own debugging style.

 - - - - - START SCRIPT - - - - -
#!/bin/bash
function DEBUG()
{
    [ "$_DEBUG" == "on" ] && $@ || :
}
for i in {1..10}
do
  DEBUG echo "I is $i"
done
 - - - - - END SCRIPT - - - - -

Run the preceding script with debugging set to "on":
# _DEBUG=on ./debug.sh
I is 1
I is 2
I is 3
I is 4
I is 5
I is 6
I is 7
I is 8
I is 9
I is 10

We prefix DEBUG before every statement where debug information is to be printed. If _DEBUG=on is not passed to the script, debug information will not be printed.

The -x flag outputs every line of script as it is executed. However, we may require only some portions of the source lines to be observed. Bash uses a set builtin to enable and disable debug printing within the script:

set -x: This displays arguments and commands upon their execution
set +x: This disables debugging
set -v: This displays input when they are read
set +v: This disables printing input

Shebang hack
The shebang can be changed from #!/bin/bash to #!/bin/bash -xv to enable debugging without any additional flags (-xv flags themselves).


Functions and arguments
A function is defined with the function command, a function name, open/close parentheses, and a function body enclosed in curly brackets:

function fname() 
{ 
    statements; 
}

Alternatively, it can be defined as:

fname() 
{ 
    statements; 
}

It can even be defined as follows (for simple functions):
fname() { statement; }

A function is invoked using its name:
$ fname ; # executes function

Arguments passed to functions are accessed positionally, $1 is the first argument, $2 is the second, and so on:
$ fname arg1 arg2 ; # passing args

The following is the definition of the function fname. In the fname function, we have included various ways of accessing the function arguments.

fname() 
{ 
   echo $1, $2; #Accessing arg1 and arg2 
   echo "$@"; # Printing all arguments as list at once 
   echo "$*"; # Similar to $@, but arguments taken as single  
   entity 
   return 0; # Return value 
 }

Arguments passed to scripts can be accessed as $0 (the name of the script):
$1 is the first argument
$2 is the second argument
$n is the nth argument
"$@" expands as "$1" "$2" "$3" and so on
"$*" expands as "$1c$2c$3", where c is the first character of IFS
"$@" is used more often than $*, since the former provides all arguments as a single string

Compare alias to function
Here's an alias to display a subset of files by piping ls output to grep. The argument is attached to the end of the command, so lsg txt is expanded to ls -ltra | grep txt:

# alias lsg='ls -ltra | grep'
# lsg txt
-rw-r--r--   1 root root    17 Jul 20 10:23 tmp.txt
-rw-r--r--   1 root root    47 Jul 20 11:11 stderr.txt
-rw-r--r--   1 root root     0 Jul 25 15:11 alfa.txt

function getIP:
# function getIP() { /usr/sbin/ifconfig $1 | /usr/bin/grep 'inet '; }
# getIP bond0
        inet 192.168.XXX.XXX  netmask 255.255.252.0  broadcast 192.168.XXX.XXX

The recursive function
A recursive function is a function that calls itself: recursive functions must have an exit condition, or they will spawn until the system exhausts a resource and crashes.

Fork bomb
This function: 
:(){ :|:& };:

spawns processes forever and ends up in a denial-of-service attack.

The & character is postfixed with the function call to bring the subprocess into the background. This dangerous code forks processes forever and is called a fork bomb.

Functions can be exported, just like environment variables, using the export command.

Reading the return value (status) of a command
The return value of a command is stored in the $? variable.

# sleep 1
# echo $?
0

The return value is called exit status. This value can be used to determine whether a command completed successfully or unsuccessfully. If the command exits successfully, the exit status will be zero, otherwise it will be a nonzero value.

Passing arguments to commands
Most applications accept arguments in different formats. Suppose -p and -v are the options available, and -k N is another option that takes a number. Also, the command requires a filename as argument. This application can be executed in multiple ways:

$ command -p -v -k 1 file
$ command -pv -k 1 file
$ command -vpk 1 file
$ command file -pvk 1


Sending output from one command to another
One of the best features of the Unix shells is the ease of combining many commands to produce a report. The output of one command can appear as the input to another, which passes its output to another command, and so on. The output of this sequence can be assigned to a variable.

The input is usually fed into a command through stdin or arguments. The output is sent to stdout or stderr. When we combine multiple commands, we usually supply input via stdin and generate output to stdout

In this context, the commands are called filters. We connect each filter using pipes, sympolized by the piping operator (|), like this:

$ cmd1 | cmd2 | cmd3

Here, we combine three commands. The output of cmd1 goes to cmd2, the output of cmd2 goes to cmd3, and the final output (which comes out of cmd3) will be displayed on the monitor, or directed to a file.

Assign the output of a sequence of commands to a variable:
# cmd_output=$(ls -ltra | grep .txt | cat -n)
# echo $cmd_output

Another method, called back quotes (some people also refer to it as back tick) can also be used to store the command output:

# cmd_output=`ls -ltra | grep .txt | cat -n`
# echo $cmd_output


Reading n characters without pressing the return key
The bash command read inputs text from the keyboard or standard input. We can use read to acquire input from the user interactively, but read is capable of more. Most input libraries in any programming language read the input from the keyboard and terminate the string when return is pressed. There are certain situations when return cannot be pressed and string termination is done based on a number of characters received (perhaps a single character).

The following statement will read n characters from input into the variable_name variable:

# read -n 2 var
ab
# echo $var
ab

Read a password in the non-echoed mode:
# read -s var

Display a message with read using the following command:
# read -p "Enter Input: " var
Enter Input: Hello.

Read the input after a timeout (seconds):
# read -t 3 var

Use a delimiter character to end the input line:
# read -d "." var
Hello
World.


Running a command until it succeeds
Sometimes a command can only succeed when certain conditions are met. For example, you can only download a file after the file is created. In such cases, one might want to run a command repeatedly until it succeeds.

Define a function in the following way:

repeat() 
{ 
  while true 
  do 
    $@ && return 
  done 
}

Alternatively, add this to your shell's rc (~/.bashrc) file for ease of use:
repeat() { while true; do $@ && return; done }

This repeat function has an infinite while loop, which attempts to run the command passed as a parameter (accessed by $@) to the function. It returns if the command was successful, thereby exiting the loop.

A faster approach
On most modern systems, true is implemented as a binary in /bin. This means that each time the aforementioned while loop runs, the shell has to spawn a process. To avoid this, we can use the shell built-in : command, which always returns an exit code 0:

repeat() { while :; do $@ && return; done }

Adding a delay
modify the function and add a delay, as follows:
repeat() { while :; do $@ && return; sleep 30; done }


Field separators and iterators
The internal field separator (IFS) is an important concept in shell scripting. It is useful for manipulating text data.

An IFS is a delimiter for a special purpose. It is an environment variable that stores delimiting characters. It is the default delimiter string used by a running shell environment.

Consider the case where we need to iterate through words in a string or comma separated values (CSV). In the first case, we will use IFS=" " and in the second, IFS=",".

The default value of IFS is a white-space

 - - - - - 

data="name,gender,rollno,location" 
#To read each of the item in a variable, we can use IFS. 
oldIFS=$IFS 
IFS=, # IFS is now a , 
for item in $data; 
do 
    echo Item: $item 
done 

IFS=$oldIFS

 - - - - - 

When IFS is set as , the shell interprets the comma as a delimiter character, therefore, the $item variable takes substrings separated by a comma as its value during the iteration.

 - - - - - 

line="root:x:0:0:root:/root:/bin/bash"
oldIFS=$IFS;
IFS=":"
count=0
for item in $line;
do

     [ $count -eq 0 ]  && user=$item;
     [ $count -eq 6 ]  && shell=$item;
    let count++
done;
IFS=$oldIFS
echo " User: " $user
echo "Shell: " $shell

 - - - - - 

Loops are very useful in iterating through a sequence of values. Bash provides many types of loops.

 - - - - -

line="root:x:0:0:root:/root:/bin/bash"
oldIFS=$IFS;
IFS=":"

for item in $line;
do
echo $item
done

 - - - - - 

Generate a List of Numbers From 1 to 50
# /bin/echo {1..50}

Generate a List of Lower Case Letters
# /bin/echo {a..z}

Generate a List of Upper Case Letters
# /bin/echo {A..Z}

http://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO-7.html

Iterate Through a Range of Numbers:

 - - - - - 

for ((i=0;i<10;i++))
{
/bin/echo $i
}

 - - - - - 

Loop Until a Condition is Met:

 - - - - - 

COUNTER=0
while [  $COUNTER -lt 10 ]; do
    echo The counter is $COUNTER
    let COUNTER=COUNTER+1 
done

 - - - - - 

A special loop called until is available with Bash. This executes the loop until the given condition becomes true

 - - - - - 

x=0; 
until [ $x -eq 9 ]; # [ $x -eq 9 ] is the condition 
do 
    let x++; echo $x; 
done

 - - - - -

Comparisons and Tests
Flow control in a program is handled by comparison and test statements. We can us if, if else, and logical operators to perform tests and comparison operators to compare data items.

IF

if condition; 
then 
    commands; 
fi


ELSE IF & ELSE

if condition;  
then 
    commands; 
else if condition; then 
    commands; 
else 
    commands; 
fi

* Note: Nesting is possible with if and else. The if conditions can be lengthy; to make them shorter we can use logical operators: 
	
	[ condition ] && action; # action executes if the condition is true
	[ condition ] || action; # action executes if the condition is false

&& is the logical AND operation and || is the logical OR operation.

Performing Mathematical Comparisons
* Note: Performing mathematical comparisons: usually, conditions are enclosed in [] square brackets. There is a space between [ or ] and operands.

[$var -eq 0 ] or [ $var -eq 0]

Perform Mathematical Tests on Variables and Values:

[ $var -eq 0 ] # It returns true when $var equal to 0. 
[ $var -ne 0 ] # It returns true when $var is not equal to 0

Important Operators:
-gt: Greater Than
-lt: Less Than
-ge: Greater Than -or- Equal To
-le: Less Than -or- Equal To

Filesystem-Related Tests
Test Different Filesystem-Related Attributes Using Different Condition Flags:
[ -f $file_var ]: This returns true if the given variable holds a regular file path or filename
[ -x $var ]: This returns true if the given variable holds a file path or filename that is executable
[ -d $var ]: This returns true if the given variable holds a directory path or directory name
[ -e $var ]: This returns true if the given variable holds an existing file
[ -c $var ]: This returns true if the given variable holds the path of a character device file
[ -b $var ]: This returns true if the given variable holds the path of a block device file
[ -w $var ]: This returns true if the given variable holds the path of a file that is writable
[ -r $var ]: This returns true if the given variable holds the path of a file that is readable
[ -L $var ]: This returns true if the given variable holds the path of a symbolic link

http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html


String Comparisons
When using string comparison, it is best to use double square brackets

[[ $str1 = $str2 ]]: This returns true when str1 equals str2, that is, the text contents of str1 and str2 are the same

[[ $str1 == $str2 ]]: It is an alternative method for string equality check

[[ $str1 != $str2 ]]: This returns true when str1 and str2 mismatch

*Note: Strings are compared alphabetically by comparing the ASCII value of the characters. For example, "A" is 0x41 and "a" is 0x61. Thus "A" is less than "a", and "AAa" is less than "Aaa".

*Note: A space is required before and after =; if it is not provided, it is not a comparison, but it becomes an assignment statement.

[[ -z $str1 ]]: This returns true if str1 holds an empty string
[[ -n $str1 ]]: This returns true if str1 holds a nonempty string


if [[ -n $str1 ]] && [[ -z $str2 ]] ;
   then
       commands;
   fi

 - - - - - 

str1="Not empty "
str2=""
if [[ -n $str1 ]] && [[ -z $str2 ]];
then
    echo str1 is nonempty and str2 is empty string.
fi

output: str1 is nonempty and str2 is empty string.

 - - - - - 

Customizing Bash W/Configuration Files
Most commands you type on the command line can be placed in a special file, to be evaluated when you log in or start a new bash session. It's common to customize your shell by putting function definitions, aliases, and environment variable settings in one of these files.

Linux has several files that might hold customization scripts. These configuration files are divided into three camps; those sourced on login, those evaluated when an interactive shell is invoked, and files evaluated whenever a shell is invoked to process a script file.

These files are evaluated when a user logs into a shell:
/etc/profile
$HOME/.profile
$HOME/.bash_login
$HOME/.bash_profile

* Note:
/etc/profile, $HOME/.profile and $HOME/.bash_profile may not be sourced if you log in via a graphical login manager. That's because the graphical window manager doesn't start a shell. When you open a terminal window, a shell is created, but it's not a login shell.

* Note: If a .bash_profile or .bash_login file is present, a .profile file will not be read.


reload .bashrc -or- .bash_profile W/O logging out & in

source ~/.bashrc

 -or-

. ~/.bashrc

 - - - - - 

Concatenating W/cat
The cat command displays or concatenates the contents of a file, but cat is capable of more. For example, cat can combine standard input data with data from a file.

The cat command is a simple and frequently used command and it stands for conCATenate.

The general syntax of cat for reading contents is as follows:
$ cat file1 file2 file3 ...

This command concatenates data from the files specified as command-line arguments and sends that data to stdout.

$ cat file.txt
        This is a line inside file.txt
        This is the second line inside file.txt

To print contents of more than one file, execute the following command:
$ cat one.txt two.txt 
        This line is from one.txt
        This line is from two.txt

The cat command not only reads from files and concatenates the data but also reads from the standard input.

The pipe operator redirects data to the cat command's standard input as follows:
OUTPUT_FROM_SOME COMMANDS | cat

The cat command can also concatenate content from files with input from a terminal.

Combine stdin and data from another file, like this:
$ echo 'Text through stdin' | cat - file.txt

The cat command has many other options for viewing files.
Getting Rid of Extra Blank Lines
Some text files contain two or more blank lines together. If you need to remove the extra blank lines, use the following syntax:

$ cat -s file

Displaying tabs as ^I
It's hard to distinguish tabs and repeated space characters. Languages such as Python may treat tabs and spaces differently. Mixtures of tabs and spaces may look similar in an editor, but appear as different indentations to the interpreter. It is difficult to identify the difference between tabs and spaces when viewing a file in a text editor. cat can also identify tabs.

Example:

$ cat file.py 
def function(): 
    var = 5 
        next = 6 
    third = 7 

$ cat -T file.py 
def function():
^Ivar = 5
^I^Inext = 6
^Ithird = 7^I

Line Numbers
The cat command's -n flag prefixes a line number to each line.

$ cat -n var_if.sh
     1  #!/bin/bash
     2
     3  #read var
     4  #/bin/echo ""
     5  #/bin/echo $var

* Note: The -n option generates line numbers for all lines, including blank lines. If you want to skip numbering blank lines, use the -b option.

* Note: The cat command never changes a file. It sends output to stdout after modifying the input according to the options. Do not attempt to use redirection to overwrite your input file. The shell creates the new output file before it opens the input file. The cat command will not let you use the same file as input and redirected output. Trying to trick cat with a pipe and redirecting the output will empty the input file.

$ cat var_if2nd.sh > var_if2nd.sh
cat: var_if2nd.sh: input file is output file

$ ls var_if2nd.sh
-rwxr-xr-x 1 root root 213 Oct  2 13:14 var_if2nd.sh
                        ^
                        | _--- 213 bytes

$ cat var_if2nd.sh | cat > var_if2nd.sh
$ ls var_if2nd.sh
-rwxr-xr-x 1 root root 0 Oct  2 13:15 var_if2nd.sh
                       ^
                       |_--- 0 bytes

 - - - - - 

Recording and Playing Back Terminal Sessions
Recording a screen session as a video is useful, but a video is an overkill for debugging terminal sessions or providing a shell tutorial.

The shell provides another option. The script command records your keystrokes and the timing of keystrokes as you type, and saves your input and the resulting output in a pair of files. The scriptreplay command will replay the session.

The script command accepts a filename as an argument. This file will hold the keystrokes and the command results. When you use the -t option, the script command sends timing data to stdout. The timing data can be redirected to a file, which records the timing info for each keystroke and output.

-a Append the output to file
-t Output timing data to standard error

# script -t 2> timingData.log -a sessionOutput.txt
Script started, file is sessionOutput.txt

# scriptreplay timingData.log sessionOutput.txt

 - - - - - 

Finding Files and File Listing
The find command uses the following strategy:  find descends through a hierarchy of files, matches files that meet the specified criteria, and performs some actions. The default action is to print the names of files and folders, which can be specified with the -print option.

To list all the files and folders descending from a given directory
$ find base_path

# find /var/log/

-or-

# find /var/log/ -print

*Note: The . specifies the current directory and .. specifies the parent directory. This convention is followed throughout the Unix filesystem.

The print option separates each file or folder name with a \n (newline). The -print0 option separates each name with a null character '\0'. The main use for -print0 is to pass filenames containing newlines or whitespace characters to the xargs command.

Example, xargs filename with space ("\n" vs "\0":
# echo "Testing" > "echo output.txt"
# find . -type f -print | xargs ls -l
ls: cannot access ./echo: No such file or directory
ls: cannot access output.txt: No such file or directory

# find . -type f -print0 | xargs -0 ls -l
-rw-r--r-- 1 root root 8 Oct  4 11:02 ./echo output.txt


The find command can select files based on glob or regular expression rules, depth in the filesystem tree, date, type of file, and more.

Search Based on Name or Regular Expression Match
The -name argument specifies a selection pattern for the name. The -name argument accepts both glob-style wildcards and regular expressions. In the following example, '*.txt' matches all the file or folder names ending with .txt and prints them.

*Note: the single quotes around *.txt. The shell will expand glob wildcards with no quotes or using double-quotes ("). The single quotes prevent the shell from expanding the *.txt and passes that string to the find command.

# find . -name '*.txt' -print
./a-output.txt
./b-output.txt
./c-output.txt

The find command has an option -iname (ignore case), which is similar to -name, but it matches filenames regardless of case.

# find . -name "a*" -print
./a-output.log

# find . -iname "a*" -print
./A-output.log
./a-output.log

The find command supports logical operations with the selection options. The   -a and -and options perform a logical AND, while the -o and -or option perform a logical OR.

$ find . \( -name '*.txt' -o -name '*.pdf' \) -print
\( and \) are used to treat -name "*.txt" -o -name "*.pdf" as a single unit.

OR Example:
# find \( -name 'a*.txt' -or -name 'a*.log' \) -print
./a-output.txt
./a-output.log

AND Example:
# find . \( -name '*s*' -and -name '*e*' -and -name '*t*' \)
./some_output.txt

The -path argument restricts the match to files that match a path as well as a name.

# find /home/tmp/ -path '*logrotate*' -name '*.conf'
/home/tmp/logrotate.d/D_output.conf
/home/tmp/logrotate.d/A_output.conf
/home/tmp/logrotate.d/C_output.conf
/home/tmp/logrotate.d/B_output.conf
/home/tmp/logrotate.d/E_output.conf

*Note: The -regex argument is similar to -path, but -regex matches the file paths based on regular expressions. Regular expressions are more complex than glob wildcards and support more precise pattern matching.

# find . -regex '.*\(\.py\|\.sh\)$' | sort
./bash1.sh
./bash2.sh
./bash3.sh
./bash4.sh
./bash5.sh
./python1.py
./python2.py
./python3.py
./python4.py
./python5.py

The -iregex option ignores the case for regular expression matches.

# find . -iregex '.*\(\.py\|\.sh\)$' | sort
./bash1.sh
./bash1.SH
./bash2.sh
./bash2.SH
./bash3.sh
./bash3.SH
./bash4.sh
./bash4.SH
./bash5.sh
./bash5.SH
 . . . . . 
  . . . .
   . . .
    . . 
     .

Negating Arguments
The find command can also exclude things that match a pattern using !

# find . ! -name "*.pdf" -print

Searching Based on the Directory Depth
The find command walks through all the subdirectories until it reaches the bottom of each subdirectory tree. By default, the find command will not follow symbolic links. The -L option will force it to follow symbolic links. If a link references a link that points to the original, find will be stuck in a loop.

The -maxdepth and -mindepth parameters restrict how far the find command will traverse. This will break the find command from an otherwise infinite search.

The -mindepth option is similar to -maxdepth, but it sets the minimum depth for which find will report matches. It can be used to find and print files that are located with a minimum level of depth from the base path.

# find . -maxdepth 1 -name "file*"
# find . -maxdepth 2 -name "file*"
./dir1/file3.txt
./dir1/file1.txt
./dir1/file2.txt

# find . -maxdepth 3 -name "file*"
./dir1/file3.txt
./dir1/file1.txt
./dir1/file2.txt

# find . -maxdepth 4 -name "file*"
./dir1/file3.txt
./dir1/file1.txt
./dir1/dir2/dir3/file5.txt
./dir1/dir2/dir3/file6.txt
./dir1/dir2/dir3/file4.txt

*Note: The -maxdepth and -mindepth option should be early in the find command. If they are specified as later arguments, it may affect the efficiency of find as it has to do unnecessary checks. For example, if -maxdepth is specified after a -type argument, the find command will first find the files having the specified -type and then filter out the files that don't match the proper depth. However, if the depth was specified before the -type, find will collect the files having the specified depth and then check for the file type, which is the most efficient way to search.


Searching Based on File Type
Unix-like operating systems treat every object as a file. There are different kinds of file, such as regular files, directory, character devices, block devices, symlinks, hardlinks, sockets...

The find command filters the file search with the -type option. Using -type, we can tell the find command to match only files of a specified type.

List only directories including descendants:
# find . -type d -print
.
./dir1
./dir1/dir2
./dir1/dir2/dir3
./logrotate.d


It is hard to list directories and files separately. But find helps to do it. List only regular files as follows:
# find . -type f -print
./dir1/file3.txt
./dir1/file1.txt
./dir1/dir2/dir3/file5.txt
./dir1/dir2/dir3/file6.txt
./dir1/dir2/dir3/file4.txt
./dir1/file2.txt


List only symbolic links as follows:
# find . -type l -print


The following table shows the types and arguments find recognizes:
 f 	regular file
 l 	symbolic link
 d 	directory
 c 	character special device
 b 	block device
 s 	socket
 p 	fifo

Searching by File Timestamp
Unix/Linux filesystems have three types of timestamp on each file. They are as follows:

Access time (-atime): The timestamp when the file was last accessed
Modification time (-mtime): The timestamp when the file was last modified
Change time (-ctime): The timestamp when the metadata for a file (such as permissions or ownership) was last modified

*Note: Unix does not store file creation time by default; however, some filesystems (ufs2, ext4, zfs, btrfs, jfs) save the creation time. The creation time can be accessed with the stat command. Given that some applications modify a file by creating a new file and then deleting the original, the creation date may not be accurate.The -atime, -mtime, and -ctime option are the time parameter options available with find. They can be specified with integer values in number of days. The number may be prefixed with - or + signs. The - sign implies less than, whereas the + sign implies greater than.

Print files that were accessed within the last seven days:
# find . -type f -atime -7 -print

Print files that have an access time exactly seven days old:
# find . -type f -atime -7 -print

Print files that have an access time older than seven days:
# find . -type f -atime +7 -print

The -mtime parameter will search for files based on the modification time; -ctime searches based on the change time.

The -atime, -mtime, and -ctime use time measured in days. The find command also supports options that measure in minutes. These are as follows:
-amin (access time)
-mmin (modification time)
-cmin (change time)

To print all the files that have an access time older than seven minutes, use the following command:
# find . -type f -amin +7 -print

The -newer option specifies a reference file with a modification time that will be used to select files modified more recently than the reference file.

Find all the files that were modified more recently than file.txt file:
# find . -type f -newer file.txt -print

*Note: The find command's timestamp flags are useful for writing backup and maintenance scripts.

Searching Based on File Size
Based on the file sizes of the files, a search can be performed:

# Files having size greater than 2 kilobytes
$ find . -type f -size +2k

# Files having size less than 2 kilobytes
$ find . -type f -size -2k

# Files having size 2 kilobytes
$ find . -type f -size 2k

different size units:
 b 	512 byte blocks
 c 	bytes
 w 	two-byte words
 k 	kilobytes (1,024 bytes)
 M 	megabytes (1,024 kilobytes)
 G 	gigabytes (1,024 megabytes)

Matching Based on File Permissions and Ownership
It is possible to match files based on the file permissions. 

The -perm option specifies that find should only match files with their permission set to a particular value. 

list out the files with specified file permissions:
# find . -type f -perm 777 -print | xargs ls -l
-rwxrwxrwx 1 root root 0 Oct  4 11:52 ./python1.py
-rwxrwxrwx 1 root root 0 Oct  4 11:52 ./python2.py

find .php files
# find . -type f -name '*.php' | xargs ls -l
-rwxr-xr-x 1 root root 0 Oct  4 16:55 ./file1.php
-rwxr-xr-x 1 root root 0 Oct  4 16:55 ./file2.php
-rwxr-xr-x 1 root root 0 Oct  4 16:55 ./file3.php
-rwxr-xr-x 1 root root 0 Oct  4 16:55 ./file4.php
-rwxr-xr-x 1 root root 0 Oct  4 16:55 ./file5.php
-rwxrwxrwx 1 root root 0 Oct  4 16:55 ./index.php

find .php files NOT 755
# find . -type f -name '*.php' ! -perm 755 | xargs ls -l
-rwxrwxrwx 1 root root 0 Oct  4 16:55 ./index.php


We can also search files based on ownership. The files owned by a specific user can be found with the -user USER option.

The USER argument can be a username or UID.

# find . -type f -name '*.php' -user root

Performing Actions on Files W/Find
The find command can perform actions on the files it identifies. You can delete files, or execute an arbitrary Linux command on the files.

The find command's -delete flag removes files that are matched instead of displaying them.

delete all .php files
# find . -type f -name "*.php" -delete


Executing a Command
The find command can be coupled with many of the other commands using the -exec option.

*Note: You must run the find command as root if you want to change the ownership of files or directories.

change all .php files to 755
# find . -type f -name "*.php" | xargs ls -l
-rw-r--r-- 1 root root 0 Oct  5 10:06 ./file1.php
-rw-r--r-- 1 root root 0 Oct  5 10:06 ./file2.php
-rw-r--r-- 1 root root 0 Oct  5 10:06 ./file3.php
-rw-r--r-- 1 root root 0 Oct  5 10:06 ./file4.php
-rw-r--r-- 1 root root 0 Oct  5 10:06 ./file5.php
-rw-r--r-- 1 root root 0 Oct  5 10:06 ./index.php

# find . -type f -name "*.php" -exec chmod 755 {} \;
# find . -type f -name "*.php" | xargs ls -l
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file1.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file2.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file3.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file4.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file5.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./index.php

change all .php file ownership apache:apache
# find . -type f -name "*.php" -exec chown apache:apache {} \;
# find . -type f -name "*.php" | xargs ls -l
-rwxr-xr-x 1 apache apache 0 Oct  5 10:06 ./file1.php
-rwxr-xr-x 1 apache apache 0 Oct  5 10:06 ./file2.php
-rwxr-xr-x 1 apache apache 0 Oct  5 10:06 ./file3.php
-rwxr-xr-x 1 apache apache 0 Oct  5 10:06 ./file4.php
-rwxr-xr-x 1 apache apache 0 Oct  5 10:06 ./file5.php
-rwxr-xr-x 1 apache apache 0 Oct  5 10:06 ./index.php

*Note: Note that the command is terminated with \;. The semicolon must be escaped or it will be grabbed by your command shell as the end of the find command instead of the end of the chown command.

Invoking a command for each file is a lot of overhead. If the command accepts multiple arguments (as chown does) you can terminate the command with a plus (+) instead of a semicolon. The plus causes find to make a list of all the files that match the search parameter and execute the application once with all the files on a single command line.

# find . -type f -name "*.php" -exec chown root:root {} +
# find . -type f -name "*.php" | xargs ls -l
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file1.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file2.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file3.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file4.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./file5.php
-rwxr-xr-x 1 root root 0 Oct  5 10:06 ./index.php

Another usage example is to concatenate all the .sh program files in a given directory and write them to a single file. 

Each of these examples will perform this action:

# find . -type f -name "*.sh" -exec cat {} \; > sh_output.txt
# find . -type f -name "*.sh" -exec cat {} > sh_output.txt \;
# find . -type f -name "*.sh" -exec cat {} > sh_output.txt +

copy all the .txt files that are older than 10 days to a directory OLD:
$ find . -type f -mtime +10 -name "*.txt" -exec cp {} OLD  \;


*Note: We cannot use multiple commands along with the -exec parameter. It accepts only a single command, but we can use a trick. Write multiple commands in a shell script (for example, commands.sh) and use it with -exec as follows:

-exec ./commands.sh {} \;

The -exec parameter can be coupled with printf to produce joutput.
# find . -type f -name "*.sh" -exec printf "Shell Script: %s\n" {} \; | sort
Shell Script: ./script1.sh
Shell Script: ./script2.sh
Shell Script: ./script3.sh
Shell Script: ./script4.sh
Shell Script: ./script5.sh


Skipping Specified Directories When Using the Find Command
Skipping certain subdirectories may improve performance during the operation of find. The technique of excluding files and directories is known as pruning. The following example shows how to use the -prune option to exclude files that match a pattern.

# find . -type d
.
./sh_1
./sh_1/sh_3
./dir1
./dir4
./dir2
./dir5
./dir3
./sh_2
./sh_2/sh_4


prune sh_* directories:
# find . -name "sh*" -prune -o -type d -print
.
./dir1
./dir4
./dir2
./dir5
./dir3


prune dir* directories:
# find . -name "dir*" -prune -o -type d -print
.
./sh_1
./sh_1/sh_3
./sh_2
./sh_2/sh_4


prune dir* directories W/-maxdepth:
# find . -maxdepth 1 -name "dir*" -prune -o -type d -print
.
./sh_1
./sh_2

 - - - - - 

Playing W/xargs
The xargs command reads a list of arguments from stdin and executes a command using these arguments in the command line. The xargs command can also convert any one-line or multiple-line text inputs into other formats, such as multiple lines (specified number of columns) or a single line, and vice versa.

The xargs command should be the first command to appear after a pipe operator. It uses standard input as the primary data source and executes another command using the values it reads from stdin as command-line arguments for the new command.

The xargs command supplies arguments to a target command by reformatting the data received through stdin. By default, xargs will execute the echo command. In many respects, the xargs command is similar to the actions performed by the find command's -exec option.

Xarg's default echo command can be used to convert multiple-line input to single-line text:

# cat xargs_file.txt
1
2
3
4
5
# cat xargs_file.txt | xargs
1 2 3 4 5

The -n argument to xargs limits the number of elements placed on each command line invocation.

# cat xargs_file.txt | xargs -n 2
1 2
3 4
5

The xargs command works by accepting input from stdin, parsing the data into individual elements, and invoking a program with these elements as the final command line arguments. By default, xargs will split the input based on whitespace and execute /bin/echo.

Splitting the input into elements based on whitespace becomes an issue when file and folder names have spaces (or even newlines) in them. The My Documents folder would be parsed into two elements My and Documents, neither of which exists.

Most problems have solutions and this is no exception.

We can define the delimiter used to separate arguments. To specify a custom delimiter for input, use the -d option:

# echo "split1Xsplit2Xsplit3Xsplit4" | xargs -d X
split1 split2 split3 split4

# echo "split1Xsplit2Xsplit3Xsplit4" | xargs -d X -n 2
split1 split2
split3 split4

The xargs command integrates well with the find command. The output from find can be piped to xargs to perform more complex actions than the -exec option can handle. If the filesystem has files with spaces in the name, the find command's -print0 option will use a 0 (NULL) to delimit the elements, which works with the xargs -0 option to parse these. 

# find . -type f -name "*.php" | xargs ls -l

# find . -type f -print0 | xargs -0 ls -l
-rw-r--r-- 1 root root 0 Oct  5 14:53 ./Hello World1.docx
-rw-r--r-- 1 root root 0 Oct  5 14:53 ./Hello World2.docx
-rw-r--r-- 1 root root 0 Oct  5 14:53 ./Hello World3.docx
-rw-r--r-- 1 root root 0 Oct  5 14:53 ./Hello World4.docx
-rw-r--r-- 1 root root 0 Oct  5 14:53 ./Hello World5.docx

# find . -type f -name '*World*' -print0 | xargs -0 rm

Count Number of Lines
# find . -type f -iname '*.txt' -print0 | xargs -0 wc -l
  6 ./file3.txt
  3 ./file1.txt
  6 ./file2.txt
 15 total

 - - - - - 

Translating W/tr
The tr command is a versatile tool in the Unix command–warrior's kit. It is used to craft elegant one-liner commands. It performs substitution of characters, deletes selected characters, and can squeeze repeated characters from the standard input. Tr is short for translate, since it translates a set of characters to another set.

The tr command accepts input through stdin (standard input) and cannot accept input through command-line arguments. It has this invocation format:
tr [options] set1 set2

perform translation of characters in the input from uppercase to lowercase:
# echo "NETWORK WARRIOR" | tr 'A-Z' 'a-z'
network warrior

You can also use special characters such as '\t', '\n', or any ASCII characters

using tr to encrypt and decrypt numeric characters:
# echo 12345 | tr '0-9' '9876543210'
87654

# echo 87654 | tr '9876543210' '0-9'
12345

The tr command can be used to encrypt text. ROT13 is a well-known encryption algorithm. In the ROT13 scheme, characters are shifted by 13 positions, thus the same function can encrypt and decrypt text:

# echo "tr came, tr saw, tr conquered." | tr 'a-zA-Z' 'n-za-mN-ZA-M'
ge pnzr, ge fnj, ge pbadhrerq.

# echo "ge pnzr, ge fnj, ge pbadhrerq." | tr 'a-zA-Z' 'n-za-mN-ZA-M'
tr came, tr saw, tr conquered.

convert each tab character to a single space:
# tr '\t' ' ' < file1.txt

The tr command has an option -d to delete a set of characters that appear on stdin using the specified set of characters to be deleted, as follows:

$ cat file.txt | tr -d  '[set1]'
#Only set1 is used, not set2

# echo "Hello123 World456" | tr -d '0-9'
Hello World

Complementing character sets
We can use a set to complement set1 using the -c flag. set2 is optional in the following command:
$ tr -c [set1] [set2]

# echo "Hello 1 World 3, What 7?" | tr -d -c '0-9 \n'
 1  3  7

The tr command can perform many text-processing tasks. For example, it can remove multiple occurrences of a character in a string. The basic form for this is as follows:

# tr -s '[set of characters to be squeezed]'

# echo 'Hello     World  ?!' | tr -s ' '
Hello World ?!


get rid of extra newlines:
# cat file10.txt

Hello


World



.....
# cat file10.txt | tr -s '\n'

Hello
World
.....

add a given list of numbers from a file
# cat file11.txt
1
3
5
7

# cat file11.txt | echo $[ $(tr '\n' '+' ) 0 ]
16


strip out the letters with the -d option, then replace the '\n' with +:
# cat file12.txt
1st
2nd
3rd
4th
5th

# cat file12.txt | tr -d [a-z] | echo "Total: $[$(tr '\n' '+') 0 ]"
Total: 15

Character classes
The tr command can use different character classes as sets. Here are the supported character classes:
  alnum 	Alphanumeric characters
  alpha 	Alphabetic characters
  cntrl 	Control (nonprinting) characters
  digit 	Numeric characters
  graph 	Graphic characters
  lower 	Lowercase alphabetic characters
  print 	Printable characters
  punct 	Punctuation characters
  space 	Whitespace characters
  upper 	Uppercase characters
  xdigit 	Hexadecimal characters

$ tr [:class:] [:class:]

# echo "hello world" | tr '[:lower:]' '[:upper:]'
HELLO WORLD

 - - - - - 

Checksum and Verification
Checksum programs are used to generate a relatively small unique key from files. We can recalculate the key to confirm that a file has not changed. Files may be modified deliberately (adding a new user changes the password file), accidentally (a data read error from a CD-ROM drive), or maliciously (a virus is inserted). Checksums let us verify that a file contains the data we expect it to.

Checksums are used by backup applications to check whether a file has been modified and needs to be backed up.

Most software distributions also have a checksum file available. Even robust protocols such as TCP can allow a file to be modified in transit. Hence, we need to know whether the received file is the original one or not by applying some kind of test.

By comparing the checksum of the file we downloaded with the checksum calculated by the distributer, we can verify that the received file is correct. If the checksum calculated from the original file at the source location matches the one calculated at the destination, the file has been received successfully.

Unix and Linux support several checksum programs, but the most robust and widely used algorithms are MD5 and SHA-1. The ms5sum and sha1sum programs generate checksum strings by applying the corresponding algorithm to the data.

# md5sum file12.txt
e3286a25d686340249bf495fba6ff00c  file12.txt

The md5sum is a 32-character hexadecimal string as given.

The integrity of a file can be verified with the generated file, like this:
# md5sum file12.txt > md5_file12.txt
# md5sum -c md5_file12.txt file12.txt
file12.txt: OK

check all the files using all .md5 information available, use this:
$ md5sum -c *.md5

SHA-1 is another commonly used checksum algorithm. It generates a 40-character hex code from the input. The sha1sum command calculates an SHA-1 checksum. Its usage is similar to md5sum.

Checksum for Directories
Checksums are calculated for files. Calculating the checksum for a directory requires recursively calculating the checksums for all the files in the directory.

The md5deep or sha1deep commands traverse a file tree and calculate checksums for all files.

# md5deep -r xargs > md5_xargsDirectory.txt
# cat md5_xargsDirectory.txt
6c26b77c925d365c33215371f63fbf1a  /tmp/xargs/file3.txt
f49856a084d991a832f6a1842071a094  /tmp/xargs/file11.txt
d4e03fcc92458f367784b2fe01335f7a  /tmp/xargs/file10.txt
5b1c01aa9b0b9986ca1048b84233f431  /tmp/xargs/md5_file12.txt
d355cb798f9bd86ac4005e9a2b426c40  /tmp/xargs/file1.txt
e3286a25d686340249bf495fba6ff00c  /tmp/xargs/file12.txt
85864c568b62c74f3990a97751b90373  /tmp/xargs/file2.txt

*Note: The -r option allows md5deep to recurse into sub-directories. The -l option enables displaying the relative path, instead of the default absolute path.

# find . -type f -name "*.php" -print0 | xargs -0 md5sum >> php_md5.txt
# cat php_md5.txt
d41d8cd98f00b204e9800998ecf8427e  ./file5.php
d41d8cd98f00b204e9800998ecf8427e  ./file2.php
d41d8cd98f00b204e9800998ecf8427e  ./file3.php
d41d8cd98f00b204e9800998ecf8427e  ./file4.php
d41d8cd98f00b204e9800998ecf8427e  ./index.php
d41d8cd98f00b204e9800998ecf8427e  ./file1.php

# md5sum -c php_md5.txt
./file5.php: OK
./file2.php: OK
./file3.php: OK
./file4.php: OK
./index.php: OK
./file1.php: OK

*Note: The md5 and SHA-1 checksums are unidirectional hash algorithms, which cannot be reversed to form the original data. These hashes are commonly used to store passwords. Only the hash for a password is stored. When a user needs to be authenticated, the password is read  and converted to the hash and that hash is compared to the stored hash. If they  are the same, the password is authenticated and access is provided.

The hash for user passwords in Linux is stored in the /etc/shadow file.
Typical line from /etc/shadow:
toor:$6$vpTrpxLo$C3WzcvlPnVo9fM5TGAXIMTpqx3aT7G4cKsxv84XVsG9rzFJK..cAEDKftSdSJZ/MutC5f5zgJty9CeqQ0ZV1V/:16419:0:99999:7:::

In some situations, we need to write scripts to edit passwords or add users. In that case, we must generate a shadow password string and write a similar line to the preceding one to the shadow file. We can generate a shadow password using openssl.

Shadow passwords are usually salted passwords. SALT is an extra string used to obfuscate and make the encryption stronger. Salt consists of random bits that are used as one of the inputs to a key derivation function that generates the salted hash for the password.

# openssl passwd -1 -salt SALT_STRING PASSWORD

# openssl passwd -1 -salt SaltItUp HorseBatteryStaple
$1$SaltItUp$A.fctQ6LXZvosStMohuMR0

 - - - - - 

Cryptographic Tools and Hashes
Encryption techniques are used to protect data from unauthorized access. Unlike the checksum algorithms we just discussed, encryption programs can reconstruct the original data with no loss.
gpg, base64

gpg (GNU privacy guard) is a widely used tool for protecting files to ensure that data is not read until it reaches its intended destination.

In order to encrypt a file with gpg, use this:
$ gpg -c filename

# gpg -c passwd.sh

In order to decrypt a gpg file, use the following command:
$ gpg filename.gpg

# gpg passwd.sh


Base64 is a group of similar encoding schemes that represent binary data in an ASCII string format by translating it into a radix-64 representation. These programs are used to transmit binary data via e-mail. The base64 command encodes and decodes the Base64 string. To encode a binary file into the Base64 format, use this:
$ base64 filename > outputfile

# base64 passwd.sh > passwd64

Alternatively, use this command:
$ cat file | base64 > outputfile

base64 can read from stdin
decode base64 data as follows:
$ base64 -d file > outputfile

# base64 -d passwd64 > passwd64_decode.sh

Alternatively, use this:
$ cat base64_file | base64 -d > outputfile

 - - - - - 

Sorting Unique and Duplicate Lines
The sort command sorts text files and stdin. It can be coupled with other commands to produce the required output. uniq is often used with sort to extract unique (or duplicate) lines.

sort a set of files:
# sort phonic.txt PHONIC.txt > sorted.txt

For a numerical sort:
$ sort -n file.txt

To sort in the reverse order:
$ sort -r file.txt

To sort by months (in the order Jan, Feb, March,...):
$ sort -M ytd.txt

To merge two already sorted files:
$ sort -m sorted1 sorted2

To find the unique lines from a sorted file:
$ sort file1.txt file2.txt | uniq

# cat PHONIC.txt PHONICa.txt
ALFA
BRAVO
CHARLIE
DELTA
ALFA
BRAVO
CHARLIE
DELTA

# sort PHONIC.txt PHONICa.txt | uniq
ALFA
BRAVO
CHARLIE
DELTA

To check whether a file has already been sorted:
# sort -c unsorted.txt
sort: unsorted.txt:3: disorder: bravo

# if sort -C unsorted.txt; then echo "-OK"; else echo "-Nope"; fi
 -Nope

Sorting According to Keys or Columns
The -k option specifies the characters to sort by. A single digit specifies the column.

# cat data.txt
redhat  1000
centos  0
opensuse        0
suse    800
debian  0
ubuntu  500

# sort -nk 2 data.txt
centos  0
debian  0
opensuse        0
ubuntu  500
suse    800
redhat  1000

# sort -rnk 2 data.txt
redhat  1000
suse    800
ubuntu  500
opensuse        0
debian  0
centos  0

# sort -hk 1 data.txt
centos  0
debian  0
opensuse        0
redhat  1000
suse    800
ubuntu  500

When -k is followed by a single integer, it specifies a column in the text file. Columns are separated by space characters.

If we need to specify keys as a group of characters (for example, characters 2-3 of column 1), we define the range as two integers separated by a period to define a character position, and join the first and last character positions with a comma.

To use the first character as the key:
$ sort -k 1,1 data.txt

# cat char.txt
alfa
bravo
chalie
delta
echo

# sorted based on column 1 characters 2-3 (i.e. 1.2,1.3)
# -b, --ignore-leading-blanks
# sort -bk 1.2,1.3 char.txt
echo
delta
chalie
alfa
bravo

To make the sort's output xargs compatible with the \0 terminator:
$ sort -z data.txt | xargs -0

text may contain unnecessary extraneous characters such as spaces. To sort them in dictionary order, ignoring punctuations:
# -b, --ignore-leading-blanks
	ignore leading blanks
# -d, --dictionary-order
	consider only blanks and alphanumeric characters

$ sort -bd unsorted.txt

uniq
The uniq command finds the unique lines in a given input (stdin or a filename command line argument) and either reports or removes the duplicated lines.

*Note: This command only works with sorted data. Hence, uniq is often used with the sort command.

# cat uniq.txt
alfa
alfa
bravo
echo
echo8
bravo

# sort uniq.txt | uniq
alfa
bravo
echo
echo8

Display only unique lines (the lines that are not repeated or duplicated in the input file):
# sort uniq.txt | uniq -u
echo
echo8

count how many times each of the lines appears in the file:
# sort uniq.txt | uniq -c
      2 alfa
      2 bravo
      1 echo
      1 echo8

find duplicate lines in the file:
# sort uniq.txt | uniq -d
alfa
bravo

To specify keys, we can use a combination of the -s and -w arguments:
-s: This specifies the number for the first N characters to be skipped
-w: This specifies the maximum number of characters to be compared

# cat uniqX.txt
a:alfa:redhat
a:alfa:centos
b:bravo:redhat
b:bravo:centos
e:echo:redhat
e:echo:centos

# sort uniqX.txt | uniq -s 1 -w 1
a:alfa:centos

# sort uniqX.txt | uniq -s 2 -w 3
a:alfa:centos
b:bravo:centos
e:echo:centos


When the output from one command is passed as input to the xargs command, it's best to use a zero-byte terminator for each element of data. Passing output from uniq to xargs is no exception to this rule. If a zero-byte terminator is not used, the default space characters are used to split the arguments in the xargs command. 

The -z option generates zero-byte-terminated output:
$ uniq -z file.txt
$ uniq -z file.txt | xargs -0 rm

 - - - - - 

Temporary File Naming and Random Numbers
Shell scripts often need to store temporary data. The most suitable location to do this is /tmp

The mktemp command will create a unique temporary file or folder name:
# mktemp
/tmp/tmp.PrEwghf4Sg

Create a temporary directory:
# mktemp -d
/tmp/tmp.TVVWSBTBHM

generate a filename without creating a file or directory:
# mktemp -u
/tmp/tmp.hMiZv6UQYp

create the temporary filename based on a template:
# mktemp template.XXX
template.S7d
# mktemp template.XXX
template.lJo

# mktemp -d template.XXX
template.QMU
# mktemp -d template.XXX
template.gC6


# ls -ltra
-rw------- 1 root root    0 Oct  6 23:45 template.S7d
-rw------- 1 root root    0 Oct  6 23:45 template.lJo
drwx------ 2 root root 4.0K Oct  6 23:45 template.QMU
drwx------ 2 root root 4.0K Oct  6 23:45 template.gC6

When providing custom templates, X will be replaced by a random alphanumeric character. Also note that there must be at least three X characters in the template for mktemp to work.

 - - - - - 

Splitting Files and Data
Splitting a large file into smaller pieces is sometimes necessary.

The split command supports M for MB, G for GB, c for byte, and w for word.

balloon file, 1 1GB file of random data:
# dd if=/dev/urandom of=./random1GB.txt bs=1G count=1

# split -b 100M random1GB.txt
# ls -l
total 2.1G
-rw-r--r-- 1 root root 1.0G Oct  6 15:12 random1GB.txt
drwxr-xr-x 5 root root 4.0K Oct  6 15:13 ..
-rw-r--r-- 1 root root 100M Oct  6 15:13 xaa
-rw-r--r-- 1 root root 100M Oct  6 15:13 xab
-rw-r--r-- 1 root root 100M Oct  6 15:13 xac
-rw-r--r-- 1 root root 100M Oct  6 15:13 xad
-rw-r--r-- 1 root root 100M Oct  6 15:13 xae
-rw-r--r-- 1 root root 100M Oct  6 15:13 xaf
-rw-r--r-- 1 root root 100M Oct  6 15:13 xag
-rw-r--r-- 1 root root 100M Oct  6 15:13 xah
-rw-r--r-- 1 root root 100M Oct  6 15:13 xai
-rw-r--r-- 1 root root 100M Oct  6 15:13 xaj
drwxr-xr-x 2 root root 4.0K Oct  6 15:13 .
-rw-r--r-- 1 root root  24M Oct  6 15:13 xak

To use numeric suffixes, use the -d argument. It is also possible to specify a suffix length using -a length:

# split -b 100M random1GB.txt -d -a5
# ls -l
total 2.1G
-rw-r--r-- 1 root root 1.0G Oct  6 15:12 random1GB.txt
drwxr-xr-x 5 root root 4.0K Oct  6 15:13 ..
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00000
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00001
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00002
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00003
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00004
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00005
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00006
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00007
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00008
-rw-r--r-- 1 root root 100M Oct  6 15:17 x00009
drwxr-xr-x 2 root root 4.0K Oct  6 15:17 .
-rw-r--r-- 1 root root  24M Oct  6 15:17 x00010

Specifying a Filename Prefix for the Split Files:
# split -b 100M random1GB.txt -d -a5 split_file
# ls -l
total 2.1G
-rw-r--r-- 1 root root 1.0G Oct  6 15:12 random1GB.txt
drwxr-xr-x 5 root root 4.0K Oct  6 15:13 ..
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00000
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00001
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00002
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00003
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00004
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00005
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00006
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00007
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00008
-rw-r--r-- 1 root root 100M Oct  6 15:19 split_file00009
drwxr-xr-x 2 root root 4.0K Oct  6 15:19 .
-rw-r--r-- 1 root root  24M Oct  6 15:19 split_file00010

split files based on the number of lines in each split rather than size:
# split -l 13 words.txt
# ls
total 1.1G
-rw-r--r-- 1 root root 1.0G Oct  6 15:12 random1GB.txt
drwxr-xr-x 5 root root 4.0K Oct  6 15:13 ..
-rw-r--r-- 1 root root  164 Oct  6 15:22 words.txt
drwxr-xr-x 2 root root 4.0K Oct  6 15:23 .
-rw-r--r-- 1 root root   86 Oct  6 15:23 xab
-rw-r--r-- 1 root root   78 Oct  6 15:23 xaa

# cat xaa
alfa
bravo
charlie
. . .
 . .
  .

# cat xab
november
oscar
papa
. . .
 . .
  .

The csplit utility splits files based on context instead of size. It can split based on line count or regular expression pattern. It's particularly useful for splitting log files.

csplit file at line number:

# csplit words.txt 5
# cat xx00
alfa
bravo
charlie
delta

# cat xx01
echo
foxtrot
golf
hotel
india
. . .
 . .
  .


csplit file W/regex:
# csplit words.txt /^uni/

# cat xx01
uniform
victor
whiskey
xray
yankee
zulu

 - - - - - 

Slicing Filenames Based on Extensions
The shell has built-in features for manipulating filenames.

The % operator will extract the name from name.extension.
# file_name=CertificationGuide.pdf
# echo ${file_name%.*}
CertificationGuide

The # operator will extract the extension:
# echo ${file_name#*.}
pdf

Here is a practical example to extract different portions of a domain name such as URL=www.google.com:

Remove Rightmost .*:
# echo ${URL%.*}
www.google

Remove Right to Leftmost .*
# echo ${URL%%.*}
www

Remove Leftmost *.
# echo ${URL#*.}
google.com

Remove Left to Rightmost *.
# echo ${URL##*.}
com

% vs %%:

# echo $URL
http://www.google.com

# echo ${URL%o*}
http://www.google.c

# echo ${URL%%o*}
http://www.g

# vs ##

# echo ${URL#*g}
oogle.com

# echo ${URL##*g}
le.com

 - - - - - 

Renaming and Moving Files in Bulk
We frequently need to move and perhaps rename a set of files. System housekeeping often requires moving files with a common prefix or file type to a new folder.

The rename command changes filenames using Perl regular expressions. By combining the find, rename, and mv commands, we can perform a lot of things.

 - - - 

#!/bin/bash
#rename all .png or .jpg files in working directory
#extract file extension from ${img##*.} variable

count=01;
for img in `find . -maxdepth 1 -type f -iname '*.png' -o -iname '*.jpg'`
do
  new=img-$count.${img##*.}

  echo "$img to $new"
  mv "$img" "$new"
  let count++
done

 - - - 

Spell–Checking and Dictionary Manipulation
The /usr/share/dict/ directory contains one or perhaps more dictionary files, which are text files with a list of words.

aspell - interactive spell checker
  list 	Produce a list of misspelled words from standard input.

# echo "People" | aspell list
# echo "Peple" | aspell list
Peple

look - display lines beginning with a given string

# look tango
tango
tangoed
tangoing
tangoreceptor
tangos

 - - - - - 

Automating Interactive Input
It's easier for casual users to interact with a set of prompts rather than remember command line flags and the proper order. For instance, a script to back up a user's work, but not to back up and lock files.

used echo -e to produce the input sequence. The -e option signals to echo to interpret escape sequences.

# echo -e "PDFs\nxlxs" > input.txt
# cat input.txt
PDFs
xlxs

The expect application is an interpreter similar to the shell. It's based on the TCL language. We'll discuss the spawn, expect, and send commands for simple automation. With the power of the TCL language behind it, expect can do much more complex tasks.

Automating W/Expect
expect does not come by default on all Linux distributions. You may have to install the expect package with your package manager

 spawn 	Runs the new target application.
 expect 	Watches for a pattern to be sent by the target application.
 send 	Sends a string to the target application.

http://www.tcl.tk/

 - - - - - 

Generating Files of any Size (i.e. Balloon File(s))
A file of random data is useful for testing. You can use such files to test application efficiency, to confirm that an application is truly input-neutral, to confirm there's no size limitations in your application, and more.

The easiest way to create a large file of a given size is with the dd command. The dd command clones the given input and writes an exact copy to the output. Input can be stdin, a device file, a regular file, and so on. Output can be stdout, a device file, a regular file, and so on.

# dd if=/dev/zero of=./zero.txt bs=1M count=1
1+0 records in
1+0 records out
1048576 bytes (1.0 MB) copied, 0.00551913 s, 190 MB/s

if defines the input file
of defines the output file
bs defines bytes in a block
count defines the number of blocks to be copied

*Note: Be careful while using the dd command as root, as it operates on a low level with the devices. A mistake could wipe your disk or corrupt the data. Double-check your dd command syntax, especially your of = parameter for accuracy.

use various units for blocksize (bs). Append any of the following characters to the number to specify the size:
 Unit size 	Code
 Byte (1 B) 	C
 Word (2 B) 	W
 Block (512 B)	B
 Kilobyte (1024 B)	K
 Megabyte (1024 KB)	M
 Gigabyte (1024 MB)	G

/dev/zero is a character special device, which returns the zero byte (\0).

If the input parameter (if) is not specified, dd will read input from stdin. If the output parameter (of) is not specified, dd will use stdout.

The dd command can be used to measure the speed of memory operations by transferring a large quantity of data to /dev/null and checking the command output.

 - - - - - 

Intersection and set Difference (A-B) on Text Files
The comm command is a utility to perform a comparison between two sorted files. It displays lines that are unique to file 1, file 2, and lines in both files. It has options to suppress one more column, making it easy to perform intersection and difference operations.

Intersection: The intersection operation will print the lines the specified files have in common with one another

Difference: The difference operation will print the lines the specified files contain and that are not the same in all of those files

Set difference: The set difference operation will print the lines in file A that do not match those in all of the set of files specified.


# cat outputA.txt
alfa
bravo
charlie
delta
echo
foxtrot
golf

# cat outputB.txt
foxtrot
golf
hotel
india
juliett

# comm outputA.txt outputB.txt
alfa
bravo
charlie
delta
echo
                foxtrot
                golf
        hotel
        india
        juliett

 The first column of the output contains lines that are only in outputA.txt. The second column contains lines that are only in outputB.txt. The third column contains the common lines from outputA.txt and outputB.txt. Each of the columns are delimited using the tab (\t) character.

 In order to print the intersection of two files, we need to remove the first and second columns and print the third column. The -1 option removes the first column, and the -2 option removes the second column, leaving the third column:

 # comm outputA.txt outputB.txt -1 -2
foxtrot
golf

Print only the lines that are uncommon between the two files by removing column 3:

# comm outputA.txt outputB.txt -3
alfa
bravo
charlie
delta
echo
        hotel
        india
        juliett

The lines can be merged by removing the tab characters with tr:

# comm outputA.txt outputB.txt -3 | tr -d '\t'
alfa
bravo
charlie
delta
echo
hotel
india
juliett

The comm command will accept a - character on the command line to read one file from stdin. This provides a way to compare more than one file with a given input.

# comm outputA.txt -
alfa
                alfa
bravo
                bravo
zulu
charlie
delta
echo
foxtrot
golf
        zulu

 - - - - - 

Working W/File Permissions, Ownership, and the Sticky Bit
Each file possesses many types of permissions. Three sets of permissions (user, group, and others) are commonly manipulated.

The user is the owner of the file, who commonly has all access permitted. The group is the collection of users (as defined by the system administrator) that may be permitted some access to the file. Others are any users other than the owner or members of the owner's group.

*Random Note:
ls --time-style

--time-style=STYLE
              with -l, show times using style STYLE: full-iso, long-iso, iso, locale, +FORMAT.  FORMAT
              is  interpreted  like  ‘date’;  if FORMAT is FORMAT1<newline>FORMAT2, FORMAT1 applies to
              non-recent files and FORMAT2 to recent files; if STYLE is prefixed with ‘posix-’,  STYLE
              takes effect only outside the POSIX locale

# ls -ltra --time-style=+"%Y-%m-%d %H:%M:%S"
total 8.0K
drwxr-xr-x 12 root root 4.0K 2017-10-11 14:56:43 ..
-rw-r--r--  1 root root    0 2017-10-11 15:01:38 file3.pdf
-rw-r--r--  1 root root    0 2017-10-11 15:01:38 file2.pdf
-rw-r--r--  1 root root    0 2017-10-11 15:01:38 file1.pdf

The first column of the output defines the file type as follows:
 -	:This is used if it is a regular file
 d	:This is used if it is a directory
 c	:This is used for a character device
 b	:This is used for a block device
 l	:This is used if it is a symbolic link
 s	:This is used for a socket
 p	:This is used for a pipe

The next nine characters are divided into three groups of three letters each (--- --- ---). The first three characters correspond to the permissions of the user (owner), the second sets of three characters correspond to the permissions of the group, and the third sets of three characters correspond to the permissions of others. Each character in the nine-character sequence (nine permissions) specifies whether permission is set or unset. If the permission is set, a character appears in the corresponding position, otherwise a - character appears in that position, which means that the corresponding permission is unset (unavailable).

The three common letters in the trio are:
r Read: When this is set, the file, device, or directory can be read.
w Write: When this is set, the file, device, or directory can be modified. On folders, this defines whether files can be created or deleted.
x execute: When this is set, the file, can be executed. On folders, this defines whether the files in the folder can be accessed.

User (permission string: rwx------): These define the options a user has. Usually, the user's permission is rw- for a data file and rwx for a script or executable. The user has one more special permission called setuid (S), which appears in the position of execute (x). The setuid permission enables an executable file to be executed effectively as its owner, even when the executable is run by another user. An example of a file with setuid permission set is -rwS------.

Group (permission string: ---rwx---): The second set of three characters specifies the group permissions. Instead of setuid, the group has a setgid (S) bit. This enables the item to run an executable file with an effective group as the owner group. But the group, which initiates the command, may be different. An example of group permission is ----rwS---.

Others (permission string: ------rwx): Other permissions appear as the last three characters in the permission string. If these are set, anyone can access this file or folder. As a rule you will want to set these bits to ---.

Directories have a special permission called a sticky bit. When a sticky bit is set for a directory, only the user who created the directory can delete the files in the directory, even if the group and others have write permissions. The sticky bit appears in the position of execute character (x) in the others permission set. It is represented as character t or T. The t character appears in the x position if the execute permission is unset and the sticky bit is set. If the sticky bit and the execute permission are set, the T character appears in the x position.

Set these permissions (rwx rw- r-) with chmod:
$ chmod u=rwx g=rw o=r file1.sh

 u 	:This specifies user permissions
 g 	:This specifies group permissions
 o 	:This specifies others permissions

Use + to add permission to a user, group, or others, and use - to remove the permissions:
$ chmod o+x file1.sh

Add the executable permission to all permission categories, that is, for user, group, and others:
$ chmod a+x file1.sh

"a" means all, user, group, and others

Use - to remove permission to a user, group, or others:
$ chmod a-x file1.sh

Permissions can be denoted with three-digit octal numbers in which each digit corresponds to user, group, and other, in that order.

Read, write, and execute permissions have unique octal numbers, as follows:
r == 4
w == 2
x == 1

We calculate the required combination of permissions by adding the octal values:
rw- == 4 + 2 = 6
r-x == 4 + 1 = 5

The permission rwx rw- r-- in the numeric method is as follows:
rwx == 4 + 2 + 1 = 7
rw- == 4 + 2 = 6
r-- == 4

Changing Ownership:
The chown command will change the ownership of files and folders.

$ chown user.group filename

# chown mysql.users mysql-safe.log
-rw-r--r--  1 mysql users    0 Oct 12 10:23 mysql-safe.log

Setting the sticky bit
The sticky bit can be applied to directories. When the sticky bit is set, only the owner can delete files, even though others have write permission for the folder.

The sticky bit is set with the +t option to chmod:
$ chmod a+t directory_name

Applying permissions recursively to files
Sometimes, you may need to change the permissions of all the files and directories inside the current directory recursively. The -R option to chmod supports recursive changes:
$ chmod -R 777 .

The -R option specifies to change the permissions recursively.
We used . to specify the path as the current working directory. This is equivalent to:
$ chmod -Rv 777 "$(pwd)"

Applying ownership recursively
The chown command also supports the -R flag to recursively change ownership:

file
$ chown -Rv user.group file1.txt
$ chown -Rv user:group file1.txt

directory
$ chown -Rv user.group dir1
$ chown -Rv user:group dir1

       -R, --recursive
              operate on files and directories recursively
       -v, --verbose
              output a diagnostic for every file processed

 - - - - - 

Making Files Immutable
When a file is made immutable, any user or super user cannot remove the file until the immutable attribute is removed from the file. Making a file immutable is one method for securing files from modification.

Use chattr to make a file immutable:
$ chattr +i file

# chattr +i mysql_2017.10-01.sql
# ls -l mysql_2017.10-01.sql
-rwxrwxrwt 1 root root 0 Oct 12 10:31 mysql_2017.10-01.sql

# rm -fr mysql_2017.10-01.sql
rm: cannot remove `mysql_2017.10-01.sql': Operation not permitted

# chattr -i mysql_2017.10-01.sql
# ls -l mysql_2017.10-01.sql
-rwxrwxrwt 1 root root 0 Oct 12 10:31 mysql_2017.10-01.sql

# rm -fr mysql_2017.10-01.sql

 - - - - - 

Generating Blank Files in Bulk
Scripts must be tested before they are used on a live system. We may need to generate thousands of files to confirm that there are no memory leaks or processes left hanging.

The touch command creates blank files or modifies the timestamp of existing files.

$ touch filename

 - - - 
for name in {1..100}.txt 
do 
  touch $name 
done
 - - - 

touch -a 	:This modifies the access time
touch -m 	:This modifies the modification time

Instead of the current time, we can specify the time and date:
$ touch -d "Fri Jun 25 20:50:14 IST 1999" filename

       -r, --reference=FILE
              use this file’s times instead of current time

# stat /etc/httpd/conf/httpd.conf
  File: `/etc/httpd/conf/httpd.conf'
  Size: 35716           Blocks: 72         IO Block: 4096   regular file
Device: fd00h/64768d    Inode: 3026423     Links: 1
Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2017-10-15 03:08:01.226329694 -0400
Modify: 2017-03-03 15:42:07.782365490 -0500
Change: 2017-03-03 15:42:07.787365637 -0500

# touch -d "2016-01-01 13:01:58" /etc/httpd/conf/httpd.conf

# stat /etc/httpd/conf/httpd.conf
  File: `/etc/httpd/conf/httpd.conf'
  Size: 35716           Blocks: 72         IO Block: 4096   regular file
Device: fd00h/64768d    Inode: 3026423     Links: 1
Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)
Access: 2016-01-01 13:01:58.000000000 -0500
Modify: 2016-01-01 13:01:58.000000000 -0500
Change: 2017-10-17 14:48:39.555981503 -0400

 - - - - - 

Symbolic Links and Their Targets

Symbolic links are pointers to other files or folders. They are similar in function to aliases in MacOS X or shortcuts in Windows.

To create a symbolic link run the following command:
$ ln -s target symbolic_link_name

print symbolic links in the current directory:
$ ls -l | grep "^l"

print all symbolic links in the current directory and subdirectories:
$ find . -type l -print

display the target path for a given symbolic link, use the readlink command:
$ readlink web_dir
        /var/www

# readlink -f /usr/lib64/libaprutil-1.so
/usr/lib64/libaprutil-1.so.0.3.9

 -f absolute path

 - - - - - 

Enumerating File Type Statistics
On Unix/Linux systems, file types are not defined by the file extension (as Microsoft Windows does). Unix/Linux systems use the file command, which examines the file's contents to determine a file's type.

print the type of a file:

$ file filename

$ file /etc/passwd
/etc/passwd: ASCII text

*Note: Bash Built-in variables
 	$# = number of arguments.
 	$@ = what parameters were passed.
 	$? = was last command successful, 0 == successful

 - - - - - 

Loopback Files
Linux filesystems normally exist on devices such as disks or memory sticks. A file can also be mounted as a filesystem. This filesystem-in-a-file can be used for testing, for customized filesystems, or even as an encrypted disk for confidential information.

Principles of Loopback Devices and Ramdisks
http://www.tldp.org/HOWTO/archived/Loopback-Root-FS/Loopback-Root-FS-2.html


To create a 1 GB ext4 filesystem in a file:

# dd if=/dev/zero of=loopback_filesystem bs=1G count=1
1+0 records in
1+0 records out
1073741824 bytes (1.1 GB) copied, 4.93061 s, 218 MB/s

# mkfs.ext4 loopback_filesystem
mke2fs 1.41.12 (17-May-2010)
loopback_filesystem is not a block special device.
Proceed anyway? (y,n) y
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
65536 inodes, 262144 blocks
13107 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=268435456
8 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376

Writing inode tables: done
Creating journal (8192 blocks): done
Writing superblocks and filesystem accounting information: done

This filesystem will be automatically checked every 22 mounts or
180 days, whichever comes first.  Use tune2fs -c or -i to override.

# file loopback_filesystem
loopback_filesystem: Linux rev 1.0 ext4 filesystem data (extents) (large files) (huge files)

Create a mount point and mount the loopback file with mkdir and mount:

# mkdir mnt

*Note: The -o loop option is used to mount loopback filesystems.
# mount -o loop loopback_filesystem mnt/

*Note: fdisk is a standard partitioning tool on Linux systems 

 - Partitioning W/fdisk
http://www.tldp.org/HOWTO/Partition/fdisk_partitioning.html

unmount W/umount

# umount loopback_filesystem

You can also use losetup
https://linux.die.net/man/8/losetup

Mounting ISO Files as Loopback
An ISO file is an archive of an optical media. We can mount ISO files in the same way that we mount physical disks using loopback mounting.

We can even use a nonempty directory as the mount path. Then, the mount path will contain data from the devices rather than the original contents, until the device is unmounted. 

# mount -o loop CentOS-7-x86_64-DVD.iso mnt_iso/
*Note: ISO is a read-only filesystem.

Flush Changes Immediately W/sync
Changes on a mounted device are not immediately written to the physical device. They are only written when the internal memory buffer is full. We can force writing with the sync command.

$ sync

 - - - - - 

Creating ISO Files and Hybrid ISO
An ISO image is an archive format that stores the exact image of an optical disk such as CD-ROM, DVD-ROM, and so on. ISO files are commonly used to store content to be burned to optical media.

We need to distinguish between bootable and non-bootable optical disks. Bootable disks are capable of booting from themselves and also running an operating system or another product. Non-bootable ISOs cannot do that.

create an ISO image from /dev/cdrom:
$ cat /dev/cdrom > image.iso

the preferred way to create an ISO image is with dd:
$ dd if=/dev/cdrom of=image.iso

The mkisofs command creates an ISO image in a file. The output file created by mkisofs can be written to CD-ROM or DVD-ROM with utilities such as cdrecord. The mkisofs command will create an ISO file from a directory containing all the files to be copied to the ISO file:

$ mkisofs -V "Label" -o image.iso source_dir/ 

We can convert standard ISO files into hybrid ISOs with the isohybrid command.

*Note: Most Linux distros don't include isohybrid by default, install the syslinux package using your package manager.

make an ISO file bootable:
$ isohybrid image.iso

The ISO file can now be written to USB storage devices.

write the ISO to a USB storage device:
$ dd if=image.iso of=/dev/sdb1

Use the appropriate device instead of /dev/sdb1, or you can use cat, as follows:

$ cat image.iso >> /dev/sdb1

Burning an ISO From the Command Line
The cdrecord command burns an ISO file to a CD-ROM or DVD-ROM.

burn the image to a CD/DVD:
$ cdrecord -v dev=/dev/cdrom image.iso

You can specify the burning speed with the -speed option. Eight, for example is the speed specified as 8x

$ cdrecord -v dev=/dev/cdrom image.iso -speed 8

A CD-ROM can be burned in multi-sessions such that we can burn data multiple times on a disk. Multisession burning can be done with the -multi option:

$ cdrecord -v dev=/dev/cdrom image.iso -multi

on a desktop computer eject will eject the tray, eject -t will close the tray.

$ eject

$ eject -t

 - - - - - 

Finding the Difference Between Files, and Patching
When multiple versions of a file are available, it is useful to highlight the differences between files rather than comparing them manually. When working with multiple developers, changes need to be distributed to the others. Sending the entire source code to other developers is time consuming. Sending a difference file instead is helpful, as it consists of only lines which are changed, added, or removed, and line numbers are attached with it. This difference file is called a patch file. We can add the changes specified in the patch file to the original source code with the patch command. We can revert the changes by patching again.

# cat v1.txt
alfa
bravo
charlie

# cat v2.txt
Alfa
bravo
charliE

Nonunified diff output (without the -u flag):
# diff v1.txt v2.txt
1c1
< alfa
---
> Alfa
3c3
< charlie
---
> charliE

The -u option produces a unified output. Unified diff output is more readable and is easier to interpret.

In unified diff, the lines starting with + are the added lines and the lines starting with - are the removed lines.

unified diff output:
# diff -u v1.txt v2.txt
--- v1.txt      2017-10-19 15:18:27.964646635 -0400
+++ v2.txt      2017-10-19 15:18:50.709296493 -0400
@@ -1,3 +1,3 @@
-alfa
+Alfa
 bravo
-charlie
+charliE

A patch file can be generated by redirecting the diff output to a file:
# diff -u v1.txt v2.txt > output.patch

The patch command can apply changes to either of the two files.

# cat v1.txt
alfa
bravo
charlie

# patch -p1 v1.txt < output.patch
patching file v1.txt

# cat v1.txt
Alfa
bravo
charliE

The diff command can act recursively against directories.

# diff -ru dir1/ dir2/
Only in dir1/: dir1-A
Only in dir2/: file10.txt
Only in dir2/: file1.txt
Only in dir2/: file9.txt
Only in dir1/: yeti.tumbler.pdf

 - - - - - 

Using Head and Tail
When examining a large file, thousands of lines long, the cat command, which will display all the lines is not suitable. We may need to print the first n lines or last n lines or print all except the last n lines or all except the first n lines, or the lines between two locations.

The head and tail commands can do this.

# head file.txt
1
2
3
4
5
6
7
8
9
10

# cat file.txt | head
1
2
3
4
5
6
7
8
9
10

# head -n3 file.txt
1
2
3

print all the lines except the last five lines:
# seq 11 | head -n -5
1
2
3
4
5
6

tail - output the last part of files. Print  the  last  10  lines of each FILE to standard output.

# seq 25 | tail
16
17
18
19
20
21
22
23
24
25

# cat file.txt | tail -n3
23
24
25

print all lines excluding the first X lines
# seq 100 | tail -n +95
95
96
97
98
99
100

tail has a special option -f or --follow, which enables tail to follow the appended lines and display them as data is added:

$ tail -f growing_file

# tail -f /var/log/messages

The dmesg command returns contents of the kernel ring buffer messages. We can use this to debug USB devices, examine disk behavior, or monitor network connectivity.

 - - - - - 

Listing Only Directories - Alternative Methods
Listing only directories via scripting is deceptively difficult. 

# ls -d */
 dir7/
 dir5/
 dir3/
 dir1/

# ls -F | grep "/$"
 ../
 dir7/
 dir5/
 dir3/
 dir1/
 ./

# ls -l | grep "^d"
 ..
 dir7
 dir5
 dir3
 dir1
 .

# find . -maxdepth 1 -type d -print
.
./dir7
./dir1
./dir5
./dir3

 - - - - - 

Fast Command-Line Navigation W/pushd & popd
pushd and popd are used to switch between multiple directories without retyping directory paths. pushd and popd create a stack of paths-a LastInFirstOut (LIFO) list of the directories we've visited.

The pushd and popd commands replace cd for changing your working directory.

push and change a directory to a path:
# pushd /var/log/
/var/log ~

Now the stack contains /var/log ~ and the current directory is changed to /var/log

push the next directory path:
# pushd /etc/
/etc /var/log ~

Now the stack contains /etc /var/log ~ and the current directory is /etc

You can push as many directory paths as needed.

view the stack contents:
# dirs
/etc/logrotate.d /etc /var/log ~

	/etc/logrotate.d /etc /var/log ~
	0                1    2        3

switch to any path in the list, example /var/log

# dirs
/etc/logrotate.d /etc /var/log ~

# pushd +2
/var/log ~ /etc/logrotate.d /etc

# pwd
/var/log

To remove a specific path from the list:
$ popd +NUMBER

# dirs
/home/tmp /etc /var/log

# popd -1
/home/tmp /var/log

pushd and popd are helpful when there are more than three directory paths, when you're only using two location cd - is easier

# cd /etc/
# cd /var/log/
# cd -
/etc
# pwd
/etc
# cd -
/var/log

 - - - - - 

Counting the Number of Lines, Words, and Characters in a File
Counting the number of lines, words, and characters in a text file is frequently useful. 

The wc utility counts lines, words, and characters. It stands for word count.

count the number of lines:
# wc -l output.txt
4 output.txt

# cat output.txt | wc -l
4

count the number of words:
# wc -w output.txt
8 output.txt

count the number of characters:
# wc -c output.txt
38 output.txt

print the number of lines, words, and characters, execute wc without any options:
# wc output.txt
 4  8 38 output.txt
 |  |  |--> characters
 |  |--> words
 |--> lines

print the length of the longest line in a file:
# wc -L output.txt
10 output.txt

 - - - - - 

Printing the Directory Tree
The tree command prints graphical trees of files and directories. The tree command does not come with pre-installed...

# yum install tree.x86_64

# tree
.
├── dir1
│   └── alfa.txt
├── dir3
├── dir5
├── dir7
│   └── zulu.pdf
├── file.txt
└── output.txt

4 directories, 4 files


display only files that match a pattern:
# tree . -P '*.txt'
.
├── dir1
│   └── alfa.txt
├── dir3
├── dir5
├── dir7
├── file.txt
└── output.txt

4 directories, 3 files


display only files that do not match a pattern:
# tree . -I '*.txt'
.
├── dir1
├── dir3
├── dir5
└── dir7
    └── zulu.pdf

4 directories, 1 file


print the size along with files and directories:
# tree -h
.
├── [4.0K]  dir1
│   └── [   0]  alfa.txt
├── [4.0K]  dir3
├── [4.0K]  dir5
├── [4.0K]  dir7
│   └── [   0]  zulu.pdf
├── [  66]  file.txt
└── [  38]  output.txt

4 directories, 4 files


The tree command can generate output in HTML as well as to a terminal.
# tree -h -H http://localhost > /var/www/html/tree.html

 - - - - - 

